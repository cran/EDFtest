<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Introduction to the EDFtest Package</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to the EDFtest Package</h1>



<p><code>EDFtest</code> package contains functions for the calculation of goodness-of-fit test statistics and their <span class="math inline">\(p\)</span>-values. The three statistics computed are the Empirical Distribution function statistics called Cramér-von Mises (<span class="math inline">\(W^{2}\)</span>), Anderson-Darling (<span class="math inline">\(A^{2}\)</span>), and Watson statistic (<span class="math inline">\(U^{2}\)</span>).</p>
<p>The statistics and their <span class="math inline">\(p\)</span>-values can be used to assess an assumed distribution. In the simplest situation you have an i.i.d. sample from some distribution <span class="math inline">\(F\)</span> and want to test the hypothesis that <span class="math inline">\(F\)</span> is a member of some specific parametric family. The following families are available: N(location=<span class="math inline">\(\mu\)</span>,scale=<span class="math inline">\(\sigma^{2}\)</span>), Gamma(shape=<span class="math inline">\(\alpha\)</span>,scale=<span class="math inline">\(\beta\)</span>), Logistic(location=<span class="math inline">\(\mu\)</span>,scale=<span class="math inline">\(s\)</span>), Laplace(location=<span class="math inline">\(\mu\)</span>,scale=<span class="math inline">\(b\)</span>), Weibull(shape=<span class="math inline">\(\alpha\)</span>,scale=<span class="math inline">\(\beta\)</span>), and Exponential(scale=<span class="math inline">\(\theta\)</span>).</p>
<div id="theory" class="section level2">
<h2>Theory</h2>
<p>This package computes goodness-of-fit test statistics <span class="math inline">\(A^2\)</span>, <span class="math inline">\(W^2\)</span>, and <span class="math inline">\(U^2\)</span> – the Anderson-Darling, Cramér-von Mises, and Watson statistics. These statistics are used to test the null hypothesis that a sample <span class="math inline">\(X_1,\ldots, X_n\)</span> is drawn from a distribution <span class="math inline">\(F\)</span> which belongs to a specified parametric family of distributions against the alternative that <span class="math inline">\(F\)</span> is not equal to any member of that parametric family.</p>
<p>The three test statistics were originally defined to test the null hypothesis that a sample, say <span class="math inline">\(U_1, \ldots, U_n\)</span>, is drawn from the uniform distribution on [0,1]. For this problem the empirical cumulative distribution function, <span class="math inline">\(F_n\)</span>, of the <span class="math inline">\(U\)</span> sample is compared to the cumulative distribution function <span class="math inline">\(F(u) = u\)</span> (on [0,1]) of the Uniform[0,1] distribution. All three statistics depend on the random function, called the empirical process, <span class="math display">\[
W_n(x) = \sqrt{n}\{F_n(x) - x\}
\]</span> defined for <span class="math inline">\(0 \le x \le 1\)</span>. The oldest of the three statistics is <span class="math inline">\(W^2\)</span> given by <span class="math display">\[
\int_0^1 W_n^2(x) \, dx.
\]</span> Anderson and Darling suggested dividing <span class="math inline">\(W_n(x)\)</span> by its standard deviation to give more weight to the tails (near 0 and 1).This gives the statistic <span class="math display">\[
A^2 = \int_0^1 \frac{W_n^2(x)}{x(1-x)} \, dx.
\]</span> Finally Watson adapted the statistic to testing for uniformity of data on a circle. In this case the circle is scaled to have circumference 1 so that starting from some point on the circle and going round the arc length traversed moves from 0 to 1. The resulting statistic is <span class="math display">\[
U^2 = \int_0^1 (W_n(u) - \int_0^1 W_n(v) \, dv )^2 \, du.
\]</span> Watson’s key observation is that this definition gives a statistic whose value does not depend on the choice of ‘some point on the circle’ mentioned above. Note, however, that the statistic can be used even if the data did not come from a circle.</p>
<p>Our package contains generic functions (<code>AD</code>, <code>CvM</code>, and <code>Watson</code>) which compute these test statistics using computing formulas which can be found, for instance, in articles by Michael Stephens in a volume edited by Ralph D’Agostino and Stephens called <em>Tests of goodness-of-fit</em>.</p>
<p>Other problems in which we want to check whether or not a sample <span class="math inline">\(X_1,\ldots,X_n\)</span> has some specific <em>continuous</em> distribution <span class="math inline">\(F_0\)</span> (such as N(0,1)) are handled by realizing that the <span class="math inline">\(X_i\)</span> have distribution <span class="math inline">\(F_0\)</span> if and only if the ‘probability integral transforms’ <span class="math inline">\(U_i=F_0(X_i)\)</span> have the standard uniform distribution. So to test the null hypothesis <span class="math inline">\(F=F_0\)</span> we do the probability integral transform and then apply one of the tests of uniformity.</p>
<p>These tests are extended to test the composite hypothesis that <span class="math inline">\(F\)</span> is <span class="math inline">\(F_0(\cdot | \theta)\)</span> for some parametric model indexed by <span class="math inline">\(\theta\)</span>. The parameter is estimated by maximum likelihood to get <span class="math inline">\(\hat\theta\)</span> and this estimate is used to produce <span class="math display">\[
\hat{U}_i = F(X_i | \hat\theta).
\]</span> Our statistics are then calculated from these <span class="math inline">\(\hat{U}_i\)</span> values which should, if the null hypothesis is correct, be approximately uniform.</p>
<p>Having computed the test statistic we want to use we then need to compute an appropriate <span class="math inline">\(p\)</span>-value. In this package we use the following limit theory to compute asymptotic <span class="math inline">\(p\)</span>-values.</p>
<p>For regular families, assuming the null hypothesis holds, each of the statistics converges in distribution to an object of the form <span class="math display">\[
\int_0^1 Y^2(u) \, du
\]</span> where <span class="math inline">\(Y\)</span> is a Gaussian process with mean function 0 and covariance function <span class="math inline">\(\rho(u,v)\)</span> which depends on the particular model being tested and usually too on the correct parameter values so that <span class="math inline">\(\rho(u,v)=\rho(u,v,\theta)\)</span>. It follows that the distribution of the integral is the same as that of <span class="math display">\[
S \equiv \sum_{i=1}^\infty \lambda_i^2 Z_i^2
\]</span> where the <span class="math inline">\(Z_i\)</span> are i.i.d. standard normal (so <span class="math inline">\(Z_i^2\)</span> is <span class="math inline">\(\chi_1^2\)</span>) and the <span class="math inline">\(\lambda\)</span> are the eigenvalues of the covariance <span class="math inline">\(\rho\)</span>. A number <span class="math inline">\(\lambda\)</span> is an eigenvalue if there is a non-zero function <span class="math inline">\(f\)</span> solving the equation <span class="math display">\[
\int_0^1 \rho(u,v,\theta) f(v) \, dv = \lambda f(u).
\]</span> In the i.i.d. sample setting the covariance function <span class="math inline">\(\rho\)</span> for the Cramér-von Mises statistic is given by <span class="math display">\[
\min\{u,v\}-uv - \psi(u,\theta)^T {\cal I}^{-1}(\theta) \psi(v,\theta).
\]</span></p>
<p>Here <span class="math inline">\({\cal I}\)</span> is the <span class="math inline">\(p \times p\)</span> Fisher information matrix for a single observation evaluated at <span class="math inline">\(\theta\)</span> and the function <span class="math inline">\(\psi\)</span> is the <span class="math inline">\(p\)</span> vector with <span class="math inline">\(i\)</span>th component <span class="math display">\[
\psi_i(v,\theta) = \frac{\partial}{\partial \theta_i} F(y|\theta)
\]</span> evaluated at the value of <span class="math inline">\(y\)</span> solving <span class="math inline">\(F(y|\theta) = v\)</span>.</p>
<p>For the Anderson-Darling statistic this covariance function must be divided by <span class="math inline">\(\sqrt{u(1-u)v(1-v)}\)</span>. For Watson’s statistic we replace <span class="math inline">\(\rho\)</span> above by <span class="math display">\[
\rho_U(u,v) = \rho(u,v) -\int_0^1 \rho(s,v) \, ds -\int_0^1 \rho(u,t)\, dt + \int_0^1\int_0^1 \rho(s,t)\, ds \, dt.
\]</span> For the built-in parametric models specified here we use the specific forms of these functions appropriate to the model; for models which are not built-in we offer another approach which is described later.</p>
<div id="built-in-distributions" class="section level3">
<h3>Built-in distributions</h3>
<p>Our computational flow for built-in distributions is then the following:</p>
<ol style="list-style-type: decimal">
<li><p>Solve the likelihood equations to compute the maximum likelihood estimate <span class="math inline">\(\hat\theta\)</span> for the data set <span class="math inline">\(x\)</span>.</p></li>
<li><p>Compute the probability integral transforms of the vector <span class="math inline">\(x\)</span> using the <span class="math inline">\(\hat\theta\)</span> distribution function for the model being tested. Then compute the value of the test statistic the user has selected.</p></li>
<li><p>Compute approximate solutions of the eigenvalue equation <span class="math display">\[
\int_0^1 \rho(u,v,\hat\theta) f(v) \, dv = \lambda f(u).
\]</span> by discretization. Specifically let <span class="math inline">\(s_i = \frac{i}{m+1}\)</span> for <span class="math inline">\(i\)</span> running from 1 to <span class="math inline">\(m\)</span> for some <span class="math inline">\(m\)</span> (in the code we take <code>m=100</code> by default) and create the matrix <span class="math inline">\(R\)</span> given by <span class="math display">\[
R_{i,j} = \rho(s_i,s_j,\hat\theta).
\]</span> Notice that the precise form of <span class="math inline">\(\rho\)</span> depends on the statistic being used and on the family of distributions being tested.</p></li>
<li><p>Then compute the <span class="math inline">\(m\)</span> eigenvalues, say <span class="math inline">\(\hat\lambda_1,\ldots,\hat\lambda_m\)</span> of <span class="math inline">\(R\)</span>.</p></li>
<li><p>Approximate the distribution of <span class="math inline">\(S\)</span> above by the distribution of <span class="math display">\[
\sum_{i=1}^m \hat\lambda_i Z_i^2.
\]</span> We use the package <code>CompQuadForm</code> to compute <span class="math inline">\(p\)</span>-values from this distribution.</p></li>
</ol>
</div>
<div id="user-supplied-distributions" class="section level3">
<h3>User supplied distributions</h3>
<p>Users can add their own distributions by providing two functions</p>
<ul>
<li><p><code>Fdist(x,thetahat, ...)</code> which takes parameter estimates and a data set <code>x</code> and computes the probability integral transform for each element of <code>x</code>. <code>Fdist</code> must return a vector of <span class="math inline">\(n\)</span> probabilities</p></li>
<li><p><code>Score(x,thetahat, ...)</code> which takes parameter estimates and a data set <code>x</code> and computes, for each entry in <code>x</code>, the component of the score function due to observation <code>x</code>. These must be returned in an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix with 1 row for each observation and 1 column for each parameter.</p></li>
</ul>
<p>The user is also expected to supply the value <code>thetahat</code> of the maximum likelihood estimate.</p>
<p>The work-flow above is then modified as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Compute the probability integral transforms of the vector <span class="math inline">\(x\)</span> using <code>Fdist(x,thetahat,...)</code>. The compute the value of the test statistic the user has selected.</p></li>
<li><p>Estimate <span class="math inline">\(\rho(s_i,s_j,\hat\theta)\)</span> using sandwich estimates of the covariance function and of the fisher information matrix. To estimate the fisher information matrix we</p></li>
</ol>
<ul>
<li><p>Call <code>Score(x,thetahat, ...)</code> to get an <span class="math inline">\(n \times p\)</span> matrix, say <span class="math inline">\(A\)</span>.</p></li>
<li><p>Compute the <span class="math inline">\(p \times p\)</span> matrix <span class="math inline">\(\hat{FI}\)</span> given by <span class="math inline">\(\hat{FI}=A^TA/n\)</span>.</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>To estimate the covariance function we compute the vector <span class="math inline">\(\hat U\)</span> of probability integral transforms using <code>Fdist</code>. Then we compute the <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(D\)</span> with <span class="math inline">\(ij\)</span>th entry <span class="math display">\[
D_{ij} = \sum_{k=1}^n 1(s_i \le \hat{U}_k)A_{kj} /n.
\]</span> We replace the matrix in Step 3 above by the <span class="math inline">\(m \times m\)</span> matrix <span class="math display">\[
R = R_0 - D (\hat{FI}^{-1}) D^T
\]</span> where the <span class="math inline">\(ij\)</span> component of the matrix <span class="math inline">\(R_0\)</span> is <span class="math inline">\(\min(s_i,s_j) - s_i s_j\)</span>.</li>
</ol>
<p>For the Anderson-Darling test we then divide <span class="math inline">\(R_{ij}\)</span> by <span class="math inline">\(\sqrt{s_i(1-s_i)s_j(1-s_j)}\)</span>. And for Watson’s test we replace <span class="math inline">\(R\)</span> by <span class="math display">\[
(I-J)R(I-J)
\]</span> where <span class="math inline">\(I\)</span> is the <span class="math inline">\(m \times m\)</span> identity matrix and <span class="math inline">\(J\)</span> is the <span class="math inline">\(m \times m\)</span> matrix with every entry given by <span class="math inline">\(1/m\)</span>. Thus we have swept out row and column means from <span class="math inline">\(R\)</span>. For the built-in cases these adjustments were made in computing <span class="math inline">\(\rho(u,v,\hat\theta)\)</span>.</p>
<p>Steps 4 and 5 are then as in the previous case.</p>
</div>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>Here is an example showing you how to use <code>EDFtest</code> package to perform goodness-of-fit tests for a given data set. We are going to use Fisher’s or Anderson’s <code>iris</code> data set for our demonstration. <code>iris</code> is a data frame with 150 observations and 5 variables which are <code>Sepal.Length</code>, <code>Sepal.Width</code>, <code>Petal.Length</code>, <code>Petal.Width</code>, and <code>Species</code>. Assumed that we have a special interest in the width of sepal in this sample. Here is a histogram of it:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">hist</span>(iris<span class="op">$</span>Sepal.Width, <span class="dt">main=</span><span class="st">&quot;Width of sepal&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>We may conclude that this sample might follow a normal or gamma distribution from above histogram. Now, let’s use the <code>EDFtest</code> package to perform the goodness-of-fit tests to justify our guess.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">library</span>(EDFtest)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="kw">set.seed</span>(<span class="st">&quot;100&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a>x=iris<span class="op">$</span>Sepal.Width</span>
<span id="cb2-4"><a href="#cb2-4"></a>shape=<span class="kw">estimate.gamma</span>(x)[<span class="dv">1</span>]</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co"># Anderson-Darling statistic and P-value</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>(<span class="dt">asq=</span><span class="kw">AD.gamma</span>(x))</span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#&gt; [1] 0.7247644</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="kw">AD.gamma.pvalue</span>(<span class="dt">a=</span>asq,<span class="dt">shape=</span>shape)<span class="op">$</span>P</span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co">#&gt; [1] 0.057625</span></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co">#Cramér-von Mises statistic and P-value</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>(<span class="dt">wsq=</span><span class="kw">CvM.gamma</span>(x))</span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co">#&gt; [1] 0.1459304</span></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="kw">CvM.gamma.pvalue</span>(<span class="dt">w=</span>wsq,<span class="dt">shape=</span>shape)<span class="op">$</span>P</span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="co">#&gt; [1] 0.02859593</span></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co">#You can also use following generic functions</span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="kw">gof.gamma</span>(x,<span class="dt">print=</span><span class="ot">TRUE</span>) <span class="co">#Imhof</span></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co">#&gt; Cramer-von Mises statistic is  0.1459304 with P-value is  0.02859593 </span></span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="co">#&gt; Anderson-Darling statistic is  0.7247644 with P-value is  0.057625 </span></span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="co">#&gt; Watson statistic is  0.14585 with P-value is  0.01936176</span></span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="kw">gof.gamma.bootstrap</span>(x,<span class="dt">M=</span><span class="dv">10000</span>) <span class="co">#bootstrap</span></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="co">#&gt; Cramer-von Mises statistic is  0.1459304 with P-value is  0.0289 </span></span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="co">#&gt; Anderson-Darling statistic is  0.7247644 with P-value is  0.0576 </span></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="co">#&gt; Watson statistic is  0.14585 with P-value is  0.0289</span></span></code></pre></div>
<p>We calculated Anderson-Darling and Cramér-von Mises statistics and <span class="math inline">\(p\)</span>-values of the sample by both <code>imhof</code> and bootstrap methods. In <code>AD.gamma.pvalue</code> and <code>CvM.gamma.pvalue</code> functions, we use <code>imhof</code> function in <code>CompQuadForm</code> package to calculated 100 eigenvalues, by default, for the calculation of their <span class="math inline">\(p\)</span>-values. Using <code>imhof</code> method, <span class="math inline">\(p\)</span>-value for <span class="math inline">\(A^{2}\)</span> is 0.057625 and for <span class="math inline">\(W^{2}\)</span> is 0.02859593. At the same time, <span class="math inline">\(p\)</span>-values by 10,000 bootstrap are 0.0289 for <span class="math inline">\(A^{2}\)</span> and 0.0576 for <span class="math inline">\(W^{2}\)</span>. Both methods are fairly consistent.</p>
<p>Now, we can do similar tests for Normal model.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">set.seed</span>(<span class="st">&quot;100&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="co"># Anderson-Darling statistic and P-value</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>(<span class="dt">asq=</span><span class="kw">AD.normal</span>(x))</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co">#&gt; [1] 0.907955</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="kw">AD.normal.pvalue</span>(<span class="dt">a=</span>asq)<span class="op">$</span>P</span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co">#&gt; [1] 0.02037737</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">#Cramér-von Mises statistic and P-value</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>(<span class="dt">wsq=</span><span class="kw">CvM.normal</span>(x))</span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">#&gt; [1] 0.1806514</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="kw">CvM.normal.pvalue</span>(<span class="dt">w=</span>wsq)<span class="op">$</span>P</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="co">#&gt; [1] 0.009486189</span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co">#You can also use following generic functions</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="kw">gof.normal</span>(x,<span class="dt">print=</span><span class="ot">TRUE</span>) <span class="co">#Imhof</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co">#&gt; Cramer-von Mises statistic is  0.1806514 with P-value is  0.009486189 </span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="co">#&gt; Anderson-Darling statistic is  0.907955 with P-value is  0.02037737 </span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co">#&gt; Watson statistic is  0.1712387 with P-value is  0.008225783</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="kw">gof.normal.bootstrap</span>(x,<span class="dt">M=</span><span class="dv">10000</span>) <span class="co">#bootstrap</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="co">#&gt; Cramer-von Mises statistic is  0.1806514 with P-value is  0.0105 </span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co">#&gt; Anderson-Darling statistic is  0.907955 with P-value is  0.0205 </span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="co">#&gt; Watson statistic is  0.1712387 with P-value is  0.0143</span></span></code></pre></div>
<p>We can see that <span class="math inline">\(p\)</span>-value for <span class="math inline">\(A^{2}\)</span> is 0.02037737 and for <span class="math inline">\(W^{2}\)</span> is 0.009486189. At the same time, <span class="math inline">\(p\)</span>-values by 10,000 bootstrap are 0.0205 for <span class="math inline">\(A^{2}\)</span> and 0.0105 for <span class="math inline">\(W^{2}\)</span>. Both methods are fairly consistent.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
